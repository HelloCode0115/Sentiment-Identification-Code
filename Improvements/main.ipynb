{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-29T12:37:34.873540Z",
     "iopub.status.busy": "2024-04-29T12:37:34.873540Z",
     "iopub.status.idle": "2024-04-29T12:37:36.624251Z",
     "shell.execute_reply": "2024-04-29T12:37:36.624251Z",
     "shell.execute_reply.started": "2024-04-29T12:37:34.873540Z"
    }
   },
   "outputs": [],
   "source": [
    "import torchvision\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.nn as nn\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "\n",
    "import email_remind \n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "torch.Size([1, 64, 224, 224])  \n",
    "torch.Size([1, 128, 112, 112])  \n",
    "torch.Size([1, 256, 56, 56])  \n",
    "torch.Size([1, 512, 28, 28])  \n",
    "torch.Size([1, 512, 14, 14])  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-29T13:00:32.728573Z",
     "iopub.status.busy": "2024-04-29T13:00:32.727571Z",
     "iopub.status.idle": "2024-04-29T13:00:32.750431Z",
     "shell.execute_reply": "2024-04-29T13:00:32.750431Z",
     "shell.execute_reply.started": "2024-04-29T13:00:32.728573Z"
    }
   },
   "outputs": [],
   "source": [
    "# vgg16 特征提取\n",
    "class vgg_16_blocks(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(vgg_16_blocks, self).__init__()\n",
    "        # 从预训练模型中拿到5层\n",
    "        vgg_model = torchvision.models.vgg16(pretrained=True)\n",
    "        self.conv1 = nn.Sequential()\n",
    "        self.conv2 = nn.Sequential()\n",
    "        self.conv3 = nn.Sequential()\n",
    "        self.conv4 = nn.Sequential()\n",
    "        self.conv5 = nn.Sequential()\n",
    "\n",
    "        for i, layer in enumerate(list(vgg_model.features)):\n",
    "            if i < 3:\n",
    "                self.conv1.add_module(str(i), layer)\n",
    "            elif i < 8:\n",
    "                self.conv2.add_module(str(i), layer)\n",
    "            elif i < 15:\n",
    "                self.conv3.add_module(str(i), layer)\n",
    "            elif i < 22:\n",
    "                self.conv4.add_module(str(i), layer)\n",
    "            elif i < 29:\n",
    "                self.conv5.add_module(str(i), layer)\n",
    "        \n",
    "        # 卷积融合特征\n",
    "        self.conv1_1 = nn.Sequential(\n",
    "            nn.Conv2d(64, 32, 3, 1, 1),\n",
    "            nn.SiLU(),\n",
    "            nn.Conv2d(32, 16, 3, 1, 1),\n",
    "        )\n",
    "        self.conv1_2 = nn.Sequential(\n",
    "            nn.Conv2d(128, 64, 3, 1, 1),\n",
    "            nn.SiLU(),\n",
    "            nn.Conv2d(64, 32, 3, 1, 1),\n",
    "            )\n",
    "        self.conv1_3 = nn.Sequential(\n",
    "            nn.Conv2d(256, 128, 3, 1, 1),\n",
    "            nn.SiLU(),\n",
    "            nn.Conv2d(128, 64, 3, 1, 1),\n",
    "            )\n",
    "        self.conv1_4 = nn.Sequential(\n",
    "            nn.Conv2d(512, 256, 3, 1, 1),\n",
    "            nn.SiLU(),\n",
    "            nn.Conv2d(256, 128, 3, 1, 1),\n",
    "            )\n",
    "        self.conv1_5 = nn.Sequential(\n",
    "            nn.Conv2d(512, 512, 3, 1, 1),\n",
    "            nn.SiLU(),\n",
    "            nn.Conv2d(512, 512, 3, 1, 1),\n",
    "            )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x1 = self.conv1(x)\n",
    "        x2 = self.conv2(x1)\n",
    "        x3 = self.conv3(x2)\n",
    "        x4 = self.conv4(x3)\n",
    "        x5 = self.conv5(x4)\n",
    "        # 上下采样到第三层的尺寸\n",
    "        x1 = F.interpolate(x1, x3.shape[-2:],mode='bilinear',\n",
    "                            align_corners=True)\n",
    "        x2 = F.interpolate(x2, x3.shape[-2:],mode='bilinear',\n",
    "                            align_corners=True)\n",
    "        x4 = F.interpolate(x4, x3.shape[-2:],mode='bilinear',\n",
    "                            align_corners=True)\n",
    "        x5 = F.interpolate(x5, x3.shape[-2:],mode='bilinear',\n",
    "                           align_corners=True)\n",
    "        x1 = self.conv1_1(x1)\n",
    "        x2 = self.conv1_2(x2)\n",
    "        x3 = self.conv1_3(x3)\n",
    "        x4 = self.conv1_4(x4)\n",
    "        x5 = self.conv1_5(x5)\n",
    "        l = torch.cat([x1, x2], dim=1)\n",
    "        h = torch.cat([x3, x4, x5], dim=1)\n",
    "        return l, h\n",
    "# 空间注意力\n",
    "\n",
    "\n",
    "class space_att(nn.Module):\n",
    "    def __init__(self, c=48):\n",
    "        super(space_att, self).__init__()\n",
    "        self.convs = nn.Sequential(\n",
    "            nn.Conv2d(c, c, 3, 1, 1),\n",
    "            nn.SiLU(),\n",
    "            nn.Conv2d(c, c, 3, 1, 1),\n",
    "            nn.SiLU(),\n",
    "            nn.Conv2d(c, 1, 1, 1, 0),\n",
    "            nn.Tanh(),\n",
    "            nn.Conv2d(1, 1, 1, 1, 0),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x1 = self.convs(x)\n",
    "        x = x*x1+x\n",
    "        return x\n",
    "# 通道注意力\n",
    "\n",
    "\n",
    "class channel_att(nn.Module):\n",
    "    def __init__(self, c=1280):\n",
    "        super(channel_att, self).__init__()\n",
    "        self.Pool = nn.Sequential(\n",
    "            nn.BatchNorm2d(c),\n",
    "            nn.AdaptiveAvgPool2d(1),\n",
    "            nn.Flatten(start_dim=-3, end_dim=-1),\n",
    "            nn.Linear(c, c//4),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(c//4, c//8),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(c//8, c//4),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(c//4, c),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        b, c, h, w = x.shape\n",
    "        y = self.Pool(x).view(b, c, 1, 1)\n",
    "        return x * y.expand_as(x)+x\n",
    "\n",
    "\n",
    "class classifier(nn.Module):\n",
    "    def __init__(self, ch=1280, cl=192, n=6):\n",
    "        super().__init__()\n",
    "\n",
    "        self.Pool = nn.AdaptiveMaxPool2d([4,4])\n",
    "        self.flatten = nn.Flatten(-3,-1)\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear((ch+cl)*4*4, 1000),\n",
    "            nn.SiLU(),\n",
    "            nn.Linear(1000, 500),\n",
    "            nn.SiLU(),\n",
    "            nn.Linear(500, 100),\n",
    "            nn.SiLU(),\n",
    "            nn.Linear(100, 20),\n",
    "            nn.SiLU(),\n",
    "            nn.Linear(20, n),\n",
    "            # nn.Softmax(dim=-1)\n",
    "        )\n",
    "        self.conv1_1_l = nn.Conv2d(cl, cl, 1, 1)\n",
    "        self.conv1_1_h = nn.Conv2d(ch, ch, 1, 1)\n",
    "\n",
    "    def forward(self, l, h):\n",
    "        l = self.conv1_1_l(l)\n",
    "        h = self.conv1_1_h(h)\n",
    "        x = torch.cat([l, h], dim=1)\n",
    "        x = self.Pool(x)\n",
    "        x =self.flatten(x)\n",
    "        x = self.fc(x)\n",
    "        return x\n",
    "    \n",
    "class my_model(nn.Module):\n",
    "    def __init__(self, ch=704,cl=48,n=6):\n",
    "        super().__init__()\n",
    "        self.vgg_16_blocks=vgg_16_blocks()\n",
    "        self.space_att=space_att(cl)\n",
    "        self.channel_att=channel_att(ch)\n",
    "        self.classifier=classifier(ch=ch,cl=cl,n=n)\n",
    "    def forward(self,x):\n",
    "        l,h=self.vgg_16_blocks(x)\n",
    "        l=l.detach()\n",
    "        h=h.detach()\n",
    "    \n",
    "        l=self.space_att(l)\n",
    "        h=self.channel_att(h)\n",
    "\n",
    "        \n",
    "        x=self.classifier(l,h)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-29T12:37:43.481232Z",
     "iopub.status.busy": "2024-04-29T12:37:43.481232Z",
     "iopub.status.idle": "2024-04-29T12:37:43.492777Z",
     "shell.execute_reply": "2024-04-29T12:37:43.492777Z",
     "shell.execute_reply.started": "2024-04-29T12:37:43.481232Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "总数据集的长度为：1980\n"
     ]
    }
   ],
   "source": [
    "train_transform = transforms.Compose([\n",
    "        transforms.Resize(250),\n",
    "        transforms.RandomResizedCrop(224),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ])\n",
    "\n",
    "full_dataset =torchvision.datasets.ImageFolder(root='images',transform=train_transform)\n",
    "\n",
    "# length 数据集总长度\n",
    "full_data_size = len(full_dataset)\n",
    "print(\"总数据集的长度为：{}\".format(full_data_size))\n",
    "\n",
    "train_size = int(0.9 * len(full_dataset))\n",
    "test_size = len(full_dataset) - train_size\n",
    "train_dataset, test_dataset = torch.utils.data.random_split(\n",
    "    full_dataset, [train_size, test_size])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-29T10:19:42.436350Z",
     "iopub.status.busy": "2024-04-29T10:19:42.435343Z",
     "iopub.status.idle": "2024-04-29T10:19:42.466425Z",
     "shell.execute_reply": "2024-04-29T10:19:42.466425Z",
     "shell.execute_reply.started": "2024-04-29T10:19:42.436350Z"
    }
   },
   "outputs": [],
   "source": [
    "torch.save(train_dataset, 'train_dataset1.pkl')\n",
    "torch.save(test_dataset, 'test_dataset1.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-29T12:37:45.538359Z",
     "iopub.status.busy": "2024-04-29T12:37:45.538359Z",
     "iopub.status.idle": "2024-04-29T12:37:45.546907Z",
     "shell.execute_reply": "2024-04-29T12:37:45.546907Z",
     "shell.execute_reply.started": "2024-04-29T12:37:45.538359Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "891 198\n"
     ]
    }
   ],
   "source": [
    "train_dataset=torch.load('train_dataset1.pkl')\n",
    "test_dataset=torch.load('test_dataset1.pkl')\n",
    "\n",
    "train_loader = DataLoader(dataset=train_dataset, batch_size=2,\n",
    "                          shuffle=True, num_workers=0, drop_last=True)\n",
    "test_loader = DataLoader(dataset=test_dataset, batch_size=1,\n",
    "                         shuffle=False, num_workers=0, drop_last=True)\n",
    "\n",
    "train_data_size = len(train_loader)\n",
    "test_data_size = len(test_loader)\n",
    "print(train_data_size, test_data_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-29T12:37:47.736487Z",
     "iopub.status.busy": "2024-04-29T12:37:47.736487Z",
     "iopub.status.idle": "2024-04-29T12:37:47.751527Z",
     "shell.execute_reply": "2024-04-29T12:37:47.751527Z",
     "shell.execute_reply.started": "2024-04-29T12:37:47.736487Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "81"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Epoch_path = \"Epoch.txt\"\n",
    "\n",
    "def get_epoch(path):\n",
    "    if not os.path.exists(path): \n",
    "        Epoch_file=open(path, \"w\")\n",
    "        Epoch_file.write(\"-1\")\n",
    "        Epoch_file.close()\n",
    "    Epoch_file=open(path, \"r\")\n",
    "    s=Epoch_file.readline()\n",
    "    Epoch_file.close()\n",
    "    return int(s)+1\n",
    "\n",
    "def set_epoch(path):\n",
    "    if not os.path.exists(path): \n",
    "        Epoch_file=open(path, \"w\")\n",
    "        Epoch_file.write(\"-1\")\n",
    "        Epoch_file.close()\n",
    "    Epoch_file=open(path, \"r\")\n",
    "    s=Epoch_file.readline()\n",
    "    Epoch_file.close()\n",
    "    Epoch_file=open(path, \"w\")\n",
    "    Epoch_file.write(str(int(s)+1))\n",
    "    Epoch_file.close()\n",
    "# print(get_epoch(\"Epoch.txt\"))\n",
    "# set_epoch(\"Epoch.txt\")\n",
    "get_epoch(Epoch_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-29T12:38:37.348050Z",
     "iopub.status.busy": "2024-04-29T12:38:37.348050Z",
     "iopub.status.idle": "2024-04-29T12:38:39.106643Z",
     "shell.execute_reply": "2024-04-29T12:38:39.106643Z",
     "shell.execute_reply.started": "2024-04-29T12:38:37.348050Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\software\\ai\\conda\\envs\\310\\lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "C:\\software\\ai\\conda\\envs\\310\\lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=VGG16_Weights.IMAGENET1K_V1`. You can also use `weights=VGG16_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "model=my_model()\n",
    "model.to(device)\n",
    "model.train()\n",
    "model_test = my_model()\n",
    "model_test.to(device)\n",
    "model_test.eval()\n",
    "pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "测试模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-29T10:19:44.657946Z",
     "iopub.status.busy": "2024-04-29T10:19:44.657946Z",
     "iopub.status.idle": "2024-04-29T10:19:45.313768Z",
     "shell.execute_reply": "2024-04-29T10:19:45.312762Z",
     "shell.execute_reply.started": "2024-04-29T10:19:44.657946Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 6])\n"
     ]
    }
   ],
   "source": [
    "for x in train_loader:\n",
    "    out= model_test(x[0].to(device))\n",
    "    print(out.shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "editable": true,
    "execution": {
     "iopub.execute_input": "2024-04-29T13:29:47.426753Z",
     "iopub.status.busy": "2024-04-29T13:29:47.426753Z",
     "iopub.status.idle": "2024-04-29T13:36:37.203863Z",
     "shell.execute_reply": "2024-04-29T13:36:37.202860Z",
     "shell.execute_reply.started": "2024-04-29T13:29:47.426753Z"
    },
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train: 100%|████████████████████████████████████████████████████████████████████████| 10/10 [06:49<00:00, 40.95s/epoch]\n"
     ]
    }
   ],
   "source": [
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.01)\n",
    "scheduler = ReduceLROnPlateau(optimizer, mode='min', factor=0.1, \n",
    "                              patience=1, verbose=False, threshold=0.001, \n",
    "                              threshold_mode='rel', cooldown=0, min_lr=0, eps=1e-08)\n",
    "ture_epoch = get_epoch(Epoch_path)\n",
    "if ture_epoch > 0:\n",
    "    model.load_state_dict(torch.load(f'weights/{ture_epoch-1}_model.pth'))\n",
    "    optimizer.load_state_dict(torch.load(\n",
    "        f'weights/{ture_epoch-1}_optimizer.pth'))\n",
    "loss_function = nn.CrossEntropyLoss()\n",
    "\n",
    "\n",
    "\n",
    "Epoch = 10\n",
    "for epoch in tqdm(range(Epoch), desc=\"train\",unit='epoch'):\n",
    "    # loss_all=None\n",
    "    log_loss = open(\"log.csv\", \"a\")\n",
    "    ture_epoch = get_epoch(Epoch_path)\n",
    "    loss_sum = 0\n",
    "    st = 0\n",
    "    for x, y in train_loader: \n",
    "        optimizer.zero_grad()\n",
    "        x = x.to(device)\n",
    "        y = y.type(torch.long).to(device)\n",
    "        out= model(x)\n",
    "        loss = loss_function(out, y)\n",
    "        # if loss_all is None:\n",
    "        #     loss_all = loss\n",
    "        # else:\n",
    "        #     loss_all += loss\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        st += 1\n",
    "        loss_sum += loss.to(\"cpu\").detach().numpy()\n",
    "    \n",
    "    \n",
    "    log_loss.write(\"{}, {}\\n\".format(ture_epoch, loss_sum/st))\n",
    "\n",
    "    name = f\"weights/{ture_epoch}\"\n",
    "    if (epoch+1) % 1 == 0:\n",
    "        torch.save(model.state_dict(), name+\"_model.pth\")\n",
    "        torch.save(optimizer.state_dict(), name+\"_optimizer.pth\")\n",
    "    log_loss.close()\n",
    "    set_epoch(Epoch_path)  # ture_epoch ++\n",
    "\n",
    "\n",
    "    if (epoch+1) % 1 == 0:\n",
    "        # 评估\n",
    "        ture_epoch = get_epoch(Epoch_path)\n",
    "        if ture_epoch > 0:\n",
    "            model_test.load_state_dict(torch.load(\n",
    "                f'weights/{ture_epoch-1}_model.pth'))\n",
    "        acc=0\n",
    "        for x, y in test_loader: \n",
    "            out= model_test(x.to(device))\n",
    "            y_pred=out.to(\"cpu\").detach().numpy()\n",
    "            y_true=y.to(\"cpu\").detach().numpy()\n",
    "            ac1=accuracy_score(y_true, y_pred.argmax(axis=-1))\n",
    "            acc+=ac1\n",
    "        acc=acc/test_loader.__len__()\n",
    "        scheduler.step(torch.tensor(acc))\n",
    "        acc_loss = open(\"acc.csv\", \"a\")\n",
    "        acc_loss.write(\"{}, {}\\n\".format(get_epoch(Epoch_path), acc))\n",
    "        acc_loss.close()\n",
    "        # email_remind.send_email(f\"acc={acc}\")\n",
    "# email_remind.send_email(None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-29T13:29:26.988290Z",
     "iopub.status.busy": "2024-04-29T13:29:26.988290Z",
     "iopub.status.idle": "2024-04-29T13:29:31.310468Z",
     "shell.execute_reply": "2024-04-29T13:29:31.309466Z",
     "shell.execute_reply.started": "2024-04-29T13:29:26.988290Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\software\\ai\\conda\\envs\\310\\lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "C:\\software\\ai\\conda\\envs\\310\\lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=VGG16_Weights.IMAGENET1K_V1`. You can also use `weights=VGG16_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 198/198 [00:03<00:00, 61.87it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.5454545454545454"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "model_test = my_model()\n",
    "\n",
    "# ture_epoch = get_epoch(Epoch_path)\n",
    "ture_epoch=79\n",
    "if ture_epoch > 0:\n",
    "    model_test.load_state_dict(torch.load(\n",
    "        f'weights/{ture_epoch-1}_model.pth'))\n",
    "\n",
    "model_test.to(device)\n",
    "model_test.eval()\n",
    "acc=0\n",
    "for x, y in tqdm(test_loader): \n",
    "# for x, y in tqdm(train_loader): \n",
    "    out= model_test(x.to(device))\n",
    "    y_pred=out.to(\"cpu\").detach().numpy()\n",
    "    y_true=y.to(\"cpu\").detach().numpy()\n",
    "    ac1=accuracy_score(y_true, y_pred.argmax(axis=-1))\n",
    "    acc+=ac1\n",
    "acc/test_loader.__len__()\n",
    "# acc/train_loader.__len__()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-04-29T10:20:07.991382Z",
     "iopub.status.idle": "2024-04-29T10:20:07.992379Z",
     "shell.execute_reply": "2024-04-29T10:20:07.992379Z",
     "shell.execute_reply.started": "2024-04-29T10:20:07.991382Z"
    }
   },
   "outputs": [],
   "source": [
    "l=(\"愤怒\",\"厌恶\",\"恐惧\",\"快乐\",\"悲伤\",\"惊喜\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
